{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96b756ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16255f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.shape = args\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.reshape((x.shape[0],)+self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9dee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowShape(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dddd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Reshape(512*7*7),\n",
    "            nn.Linear(512*7*7,1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        return self.disc(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3070f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 7*7*256),\n",
    "            Reshape(256, 7, 7),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.gen(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d36a2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 1024\n",
    "batch_size = 256\n",
    "lr = 2e-4\n",
    "num_epochs = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "fixed_noise = torch.randn((100, z_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33349ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [Resize(112), ToTensor(), Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]\n",
    ")\n",
    "cifar = datasets.CIFAR10(root='dataset/cifar10/',transform=transforms, download=True)\n",
    "loader = DataLoader(dataset=cifar, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# dataset = datasets.ImageFolder(root='...', transform=transforms) \n",
    "# loader = DataLoader(dataset=cifar, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866f72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator().to(device)\n",
    "gen = Generator(z_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c5c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d30fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    \n",
    "    \n",
    "def save_fake_img(index):\n",
    "    fake_images = gen(fixed_noise)\n",
    "    fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "    print('Saving', fname)\n",
    "    save_image(fake_images, os.path.join(sample_dir, fname), nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef7c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [98/1563], Loss D: 0.0415, loss G: 1.5968, Time: 33.5944s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "begin = time.time()\n",
    "d_losses, g_losses = [], []\n",
    "for epoch in range(0, num_epochs):\n",
    "    since = time.time()\n",
    "    for idx, (real, _) in  enumerate(loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        real = real.to(device)\n",
    "        train_batch_size  = real.shape[0]\n",
    "        \n",
    "        noise = torch.randn((train_batch_size, z_dim)).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        lossD_real = criterion(disc_real,torch.ones_like(disc_real))\n",
    "        disc_fake= disc(fake).reshape(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        opt_disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        d_losses.append(lossD.item())\n",
    "\n",
    "        output = disc(fake).reshape(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        opt_gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step() \n",
    "        g_losses.append(lossG.item())\n",
    "        \n",
    "        if (idx+1) % 98 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}], Step [{idx+1}/{len(loader)}], Loss D: {d_losses[-1]:.4f}, loss G: {g_losses[-1]:.4f}, Time: {time.time() - since:.4f}s\"\n",
    "            )\n",
    "\n",
    "    print(\n",
    "            f\"Total Time: {time.time() - begin:.4f}s\"\n",
    "        )\n",
    "\n",
    "    save_fake_img(epoch+1)\n",
    "    if (epoch)+1 % 50 == 0:\n",
    "        fname = 'fake_images-{0:0=4d}.png'.format(epoch+1)\n",
    "        Image(os.path.join(sample_dir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(disc.state_dict(), 'D_LS.ckpt')\n",
    "torch.save(gen.state_dict(), 'G_LS.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a09e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses, '-')\n",
    "plt.plot(g_losses, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "randn_noise = torch.randn((100, z_dim)).to(device)\n",
    "fake = gen(randn_noise)\n",
    "save_image(fake,os.path.join(sample_dir, 'test_result.png'), nrow = 10)\n",
    "\n",
    "Image(os.path.join(sample_dir, 'test_result.png'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4dac63c",
   "metadata": {},
   "source": [
    "!pip install opencv-python\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "vid_fname = 'gans_training.avi'\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in  f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(vid_fname, cv2.VideoWriter_fourcc(*'MJPG'), 8, (342, 342))\n",
    "[out.write(cv2.imread(fname)) for fname in  files]\n",
    "out.release()\n",
    "FileLink('gans_training.avi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
